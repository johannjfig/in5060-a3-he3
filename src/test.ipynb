{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyxdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyxdf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m argv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyxdf'"
     ]
    }
   ],
   "source": [
    "import pyxdf\n",
    "import numpy as np\n",
    "from sys import argv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf_data_path = Path(\"xdf_data\")\n",
    "\n",
    "xdf_filepaths = list(xdf_data_path.rglob(\"*.xdf\"))\n",
    "\n",
    "xdf_data = {str(x).split(\"/\")[1] : pyxdf.load_xdf(str(x)) for x in xdf_filepaths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def separate_trials_expmakers(exp_list):\n",
    "    for i, string in enumerate(exp_list[1:]):\n",
    "        if string == \"task_block_start|BOX_BLOCK\":\n",
    "            return [exp_list[0:i+1], exp_list[i+1:]], False\n",
    "        elif string == \"task_block_start|JEBSEN_TAYLOR\":\n",
    "            return [exp_list[i+1:], exp_list[0:i+1]], True\n",
    "    # If no empty string is found, return the whole list as the first trial, second is empty\n",
    "    raise Exception(f\"Separate exp: {exp_list}\")\n",
    "\n",
    "def separate_trials_latmarkers(lat_list):\n",
    "    for i, string in enumerate(lat_list[1:]):\n",
    "        if string == \"repetition_start|2\": # Do I need to do a similar logic like above?\n",
    "            return lat_list[0:i+1], lat_list[i+1:]\n",
    "    # If the marker is not found, return the whole list as first trial, second is empty\n",
    "    raise Exception(f\"Separate lat: {lat_list}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_participant_trials(pnum):\n",
    "    participant_trials = {\n",
    "        \"move_cans\": {},\n",
    "        \"move_blocks\": {}\n",
    "    }\n",
    "\n",
    "    exp_trial_jhft, exp_trial_blocks = None, None\n",
    "    lat_trial_0, lat_trial_1 = None, None\n",
    "    trials_swapped = False\n",
    "    exp_markers_reached = False\n",
    "    lat_markers_reached = False\n",
    "    \n",
    "    data, header = xdf_data[f\"sub-{pnum:03}\"]  # Assuming xdf_data is already loaded\n",
    "    for stream in data:\n",
    "        stream_series = stream[\"time_series\"]\n",
    "        stream_name = stream[\"info\"][\"name\"][0]\n",
    "        stream_series_list = list(stream_series)\n",
    "        \n",
    "        if stream_name == \"LatencyMarkers\":\n",
    "            if lat_markers_reached:\n",
    "                raise Exception(\"Duplication of latency markers!\")\n",
    "            lat_markers_reached = True\n",
    "            \n",
    "            stream_series_np = np.array(stream_series).flatten()\n",
    "            lat_trial_0, lat_trial_1 = separate_trials_latmarkers(list(stream_series_np))\n",
    "            if exp_markers_reached:\n",
    "                participant_trials[\"move_cans\"][\"exp_markers\"] = exp_trial_jhft\n",
    "                participant_trials[\"move_blocks\"][\"exp_markers\"] = exp_trial_blocks\n",
    "                \n",
    "                if trials_swapped:\n",
    "                    participant_trials[\"move_cans\"][\"lat_markers\"] = lat_trial_1\n",
    "                    participant_trials[\"move_blocks\"][\"lat_markers\"] = lat_trial_0\n",
    "                else:\n",
    "                    participant_trials[\"move_cans\"][\"lat_markers\"] = lat_trial_0\n",
    "                    participant_trials[\"move_blocks\"][\"lat_markers\"] = lat_trial_1\n",
    "        elif stream_name == \"ExpMarkers\" and not exp_markers_reached:\n",
    "            exp_markers_reached = True\n",
    "            \n",
    "            stream_series_np = np.array(stream_series).flatten()\n",
    "            # Not swapped can trial and then block trial\n",
    "            [exp_trial_jhft, exp_trial_blocks], trials_swapped = separate_trials_expmakers(list(stream_series_np))\n",
    "            \n",
    "            if lat_markers_reached:\n",
    "                participant_trials[\"move_cans\"][\"exp_markers\"] = exp_trial_jhft\n",
    "                participant_trials[\"move_blocks\"][\"exp_markers\"] = exp_trial_blocks\n",
    "                \n",
    "                if trials_swapped:\n",
    "                    participant_trials[\"move_cans\"][\"lat_markers\"] = lat_trial_1\n",
    "                    participant_trials[\"move_blocks\"][\"lat_markers\"] = lat_trial_0\n",
    "                else:\n",
    "                    participant_trials[\"move_cans\"][\"lat_markers\"] = lat_trial_0\n",
    "                    participant_trials[\"move_blocks\"][\"lat_markers\"] = lat_trial_1\n",
    "\n",
    "    if not lat_markers_reached or not exp_markers_reached:\n",
    "        raise Exception(\"Some of the required markers were not reached!\")\n",
    "    \n",
    "    return participant_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_trials = {}\n",
    "for i in range(1, len(xdf_data) + 1):\n",
    "    try:\n",
    "        participants_trials[i] = collect_participant_trials(i)\n",
    "    except Exception as e:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_moved_blocks(p_trials):\n",
    "    exp_markers = p_trials[\"move_blocks\"][\"exp_markers\"]\n",
    "    accepted_tasks = list(filter(lambda x: x.startswith(\"task_accept|\"), exp_markers))\n",
    "    moved_blocks = [int(x.split(\"task_accept|\")[-1]) for x in accepted_tasks]\n",
    "    return moved_blocks\n",
    "\n",
    "def find_moved_blocks_latencies(p_trials):\n",
    "    lat_markers = p_trials[\"move_blocks\"][\"lat_markers\"]\n",
    "    lat_applied = list(filter(lambda x: x.startswith(\"latency_applied\"), lat_markers))[:5]\n",
    "    latencies = [x.split(\"|\")[1] for x in lat_applied]\n",
    "    return latencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in participants_trials:\n",
    "    # participant_moved_blocks = find_moved_blocks(participants_trials[i])\n",
    "    # print(f\"{i} : {len(participant_moved_blocks)} : {participant_moved_blocks}\")\n",
    "    latencies = find_moved_blocks_latencies(participants_trials[i])\n",
    "    print(f\"{i} : {latencies}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)     # show all columns\n",
    "pd.set_option(\"display.max_rows\", None)        # show all rows (optional)\n",
    "pd.set_option(\"display.width\", None)           # don't wrap columns\n",
    "pd.set_option(\"display.max_colwidth\", None)    # don't truncate cell content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xlsx = pd.read_excel(\"questionnaire_data-561422-2025-11-07-1643.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_dict = {i : [] for i in range(1, 6)}\n",
    "for xlsx_col in xlsx.columns:\n",
    "    for i in range(1, 6):\n",
    "        if str(xlsx_col).endswith(f\"{i}\"):\n",
    "            xlsx_dict[i].append(xlsx_col)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
